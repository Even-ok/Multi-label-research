### *Simple and Robust Loss Design for Multi-Label Learning with Missing Labels*

1. **要做这项工作的动机**

MLML(multi-label with missing label) 领域，大多利用标签纠正或者转移矩阵，来估计出缺失的标签。那么就需要引入额外的模型，或者训练模式。本文在损失函数上进行调整，不需要引入额外模型。

2. **本文的主要贡献**

- 观测到，模型可以在训练早期识别出false negatives
- 关于MLML领域的loss的系统的学习
- 在损失函数中加入了两个创新型思想——hill loss & self-paced loss correction
- 在多个数据集上综合验证

3. **提出这些改变的动机**

- 根绝memorization effect，DNNs总是首先去学习简单的模式，然后再学习去记忆，所以先把难以区分的missing label先剔除掉，在早期能够让模型取得较好的效果



------

#### 关于文章的一些细节

1. **关于多标签分类的分类结果**

- TP(True Positive): 属于该类的样本，被正确分类到该类
- **FN(False Negative): 不属于该类的样本，被错误分类到该类**(经验证，会造成较大影响)
- TN(True Negative): 属于该类的样本，却被错误分类到其他类
- FP(False Positive): 不属于该类的样本，被正确分类到其他类

2. 关于Fig. 2的解读

![image-20221027205816834](C:\Users\liangyiwen\AppData\Roaming\Typora\typora-user-images\image-20221027205816834.png)

这张图的意思应该是，有0.1的概率被判为positive/missing/negative的数量有多少！（图a）