### *Simple and Robust Loss Design for Multi-Label Learning with Missing Labels*

1. **要做这项工作的动机**

MLML(multi-label with missing label) 领域，大多利用标签纠正或者转移矩阵，来估计出缺失的标签。那么就需要引入额外的模型，或者训练模式。本文在损失函数上进行调整，不需要引入额外模型。

2. **本文的主要贡献**

- 观测到，模型可以在训练早期识别出false negatives
- 关于MLML领域的loss的系统的学习
- 在损失函数中加入了两个创新型思想——hill loss & self-paced loss correction
- 在多个数据集上综合验证

3. **提出这些改变的动机**

- 根绝memorization effect，DNNs总是首先去学习简单的模式，然后再学习去记忆，所以先把难以区分的missing label先剔除掉，在早期能够让模型取得较好的效果

4. 简述本文针对loss function的改进

- 对于$L^+$， 本文用了Focal margin + SPLC，Focal margin用来强调semi-hard positive，避免focal loss只强调hard positive的情况；

- 对于$L^-$，本文用了Hill loss, 也是因为要降低hard negative部分的强调，重视一下中间semi-hard部分
- SPLC： 主要是解决missing label的问题，根据概率分布确定一个阈值$\tau$

------

#### 关于文章的一些细节

1. **关于多标签分类的分类结果**

- TP(True Positive): 属于该类的样本，被正确分类到该类
- **FN(False Negative): 不属于该类的样本，被错误分类到该类**(经验证，会造成较大影响)
- TN(True Negative): 属于该类的样本，却被错误分类到其他类
- FP(False Positive): 不属于该类的样本，被正确分类到其他类

2. 关于Fig. 2的解读

![image-20221027205816834](C:\Users\liangyiwen\AppData\Roaming\Typora\typora-user-images\image-20221027205816834.png)

这张图的意思应该是，有0.1的概率被判为positive/missing/negative的数量有多少！（图a）

3. 文中所提到的/对比的一些loss function：

- BCE（binary classification error）
- WAN(single label那篇提到的，有点忘了)
- Label smoothing
- Hill loss
- ASL(Asymmetric loss)
- pseudo label method( label correction 的method, from **Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks**)